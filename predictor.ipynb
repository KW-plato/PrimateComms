{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ivjlHhwbzxDtOQXDt0uBCw_qWMOmM6Rq",
      "authorship_tag": "ABX9TyN8lxfgosHDyWPrZuaqGt2G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KW-plato/PrimateComms/blob/main/predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6ufHIyVdIKE"
      },
      "source": [
        "**Script for demo of call-type prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jXVBuKfdFQI"
      },
      "source": [
        "%pip install pydub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5XnFwoW0KV6"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydub\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from handlers.datahandler import AudioSpectDataset\n",
        "from models.chimp_model import ChimpCallClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmXiYmOTWGz9"
      },
      "source": [
        "\"\"\"\n",
        "Helper functions\n",
        "\"\"\"\n",
        "#adds a processed clip to list of clips to be predicted\n",
        "def add_processed_clip(recording, segment, t1, t2, len, spec, label):\n",
        "    spec_list.append({\n",
        "        'recording': recording,\n",
        "        'segment': segment,\n",
        "        't1': t1,\n",
        "        't2': t2,\n",
        "        'len (s)': len,\n",
        "        'spectrogram': spec,\n",
        "        'label': label\n",
        "    })\n",
        "\n",
        "#Pretty prints the predicted call labels\n",
        "def pretty_print(df):\n",
        "    print(\"{0:*^80s}\".format(df.iloc[1]['recording']))\n",
        "    print(\"{0:^15s} {1:^15s} {2:^10s} {3:<40s}\".format(\"Start Time\",\"End Time\",\"Duration\",\"Call Type/Comment\"))\n",
        "    for i,row in df.iterrows():\n",
        "        print(\"{0:^15.4f} {1:^15.4f} {2:^10.4f} {3:<40s}\".format(row['t1'], row['t2'], row['len (s)'], row['label']))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rktrS3B20okI"
      },
      "source": [
        "datasrc = \"/Techspace/Chimp/data/Demo\"\n",
        "detector_output = \"ARU18_20120410_090000.txt\"\n",
        "audio_file = \"ARU18_20120410_090000.wav\"\n",
        "spec_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQJ48PqNWSH6"
      },
      "source": [
        "#Create temporary directories\n",
        "temp_dir = os.path.join(datasrc,\"temp\")\n",
        "if not os.path.isdir(temp_dir):\n",
        "    os.makedirs(temp_dir)\n",
        "\n",
        "temp_wavs = os.path.join(temp_dir, \"wav\", audio_file.rstrip(\".wav\"))\n",
        "if not os.path.isdir(temp_wavs):\n",
        "    os.makedirs(temp_wavs)\n",
        "\n",
        "temp_specs = os.path.join(temp_dir, \"specs\", audio_file.rstrip(\".wav\"))\n",
        "if not os.path.isdir(temp_specs):\n",
        "    os.makedirs(temp_specs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXanb_eK0mOT"
      },
      "source": [
        "#Read detector output and the audio recording\n",
        "chimp_calls = pd.read_csv(os.path.join(datasrc,detector_output), delimiter='\\t', encoding='utf-16')\n",
        "newAudio = pydub.AudioSegment.from_wav(os.path.join(datasrc, audio_file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5J28Syu6QWi"
      },
      "source": [
        "#The contents of the detector's output\n",
        "display(chimp_calls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omEA_FyGbHJH"
      },
      "source": [
        "# Reads the timestamps of start and end points of each chimp volcalization available from detector's output\n",
        "# Clips the recording at the timestamps, converts into spectrogram, stores in temporary directory and creates a list\n",
        "for r, row in chimp_calls.iterrows():\n",
        "    segment = \"{} - {}\".format(row[\"Begin Time (s)\"], row[\"End Time (s)\"])\n",
        "    dur = row[\"End Time (s)\"] - row[\"Begin Time (s)\"]\n",
        "    if dur >= 0.5:\n",
        "        start = row[\"Begin Time (s)\"] * 1000\n",
        "        end = row[\"End Time (s)\"] * 1000\n",
        "        finalAudio = newAudio[start:end]\n",
        "        if finalAudio.channels > 1:\n",
        "            finalAudio = finalAudio.set_channels(1)\n",
        "        filename = os.path.join(temp_wavs, str(start) + '_' + str(end) + '.wav')\n",
        "        finalAudio.export(filename, format='wav')\n",
        "        sampling_rate, input_clip = wavfile.read(filename)\n",
        "        clip_len = len(input_clip)\n",
        "        if sampling_rate != 44100:\n",
        "            input_clip = signal.resample(input_clip, int(clip_len * 44100 / sampling_rate))\n",
        "            sampling_rate = 44100\n",
        "        x1 = x2 = 0\n",
        "        clip_len = len(input_clip)\n",
        "        while ( x2 <= clip_len):\n",
        "            x2 = int(x1 + 0.5 * sampling_rate)\n",
        "            t1 = row[\"Begin Time (s)\"] + x1 / sampling_rate\n",
        "            if x2 > clip_len:\n",
        "                t2 = row[\"End Time (s)\"]\n",
        "                x1 = int(clip_len - 0.5 * sampling_rate)\n",
        "            else:\n",
        "                t2 = row[\"Begin Time (s)\"] + x2 / sampling_rate\n",
        "            l = t2 - t1\n",
        "            piece = input_clip[x1:x2]\n",
        "            try:\n",
        "                _, _, spectrogram = signal.spectrogram(\n",
        "                    x=piece,\n",
        "                    fs=sampling_rate,\n",
        "                    nfft=512,\n",
        "                    noverlap=427,\n",
        "                    detrend=False,\n",
        "                    window=signal.get_window('hamming', 512)\n",
        "                )\n",
        "                if spectrogram.shape == (257, 254):\n",
        "                    temp = os.path.join(temp_specs, str(r + 1) + \"_\" + str(x1) + \".spec\")\n",
        "                    with open(temp, 'wb') as f_save:\n",
        "                        np.save(f_save, spectrogram)\n",
        "                    add_processed_clip(audio_file, segment, t1, t2, l, temp, 'undecoded')\n",
        "                else:\n",
        "                    add_processed_clip(audio_file, segment, t1, t2, l, \"Unavailable\", \"specgram shape {}\".format(spectrogram.shape))\n",
        "            except Exception as e:\n",
        "                add_processed_clip(audio_file, segment, t1, t2, l, \"Unavailable\", e)\n",
        "            x1 = x2\n",
        "    else:\n",
        "        add_processed_clip(audio_file, segment, row[\"Begin Time (s)\"], row[\"End Time (s)\"], dur, \"Unavailable\", \"Segment smaller than 500ms\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_VPLwaVb2bi"
      },
      "source": [
        "#Feeds the volcalization segments into the trained model\n",
        "#Stores the prediction for the entire recording\n",
        "if spec_list:\n",
        "    df = pd.DataFrame(spec_list, columns=['recording','segment','t1','t2', 'len (s)', 'spectrogram', 'label'])\n",
        "    df_train = df.loc[df['label'] == 'undecoded',['spectrogram', 'label']].reset_index()\n",
        "\n",
        "    pred_data = AudioSpectDataset(df_train['spectrogram'].to_list(), df_train['label'].to_list())\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    saved_model = torch.load(os.path.join(datasrc, \"SPECGRAM_final_other.pth\"), map_location=torch.device('cpu'))\n",
        "    label_dict = saved_model['labels']\n",
        "    classifier = ChimpCallClassifier(\n",
        "        num_labels=len(label_dict),\n",
        "        spectrogram_shape=saved_model['spectrogram_shape'],\n",
        "        dropout=saved_model['dropout']\n",
        "    ).float()\n",
        "\n",
        "    classifier.load_state_dict(saved_model['model'])\n",
        "    classifier.eval()\n",
        "    dataloaders_test = torch.utils.data.DataLoader(pred_data, batch_size=1, shuffle=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, samples in enumerate(dataloaders_test):\n",
        "            input = samples['spectrogram'].to(device)\n",
        "            outputs = classifier(input)\n",
        "            pred = int(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "            calltype = label_dict[pred]\n",
        "            pos = df_train.at[df_train.index[i],'index']\n",
        "            df.at[df.index[pos],'label'] = calltype\n",
        "\n",
        "    df = df[['recording','segment','t1','t2', 'len (s)', 'label']]\n",
        "    df.to_csv(os.path.join(datasrc,audio_file.rstrip(\".wav\") + '.csv'), index=False, header=True)\n",
        "else:\n",
        "    print(\"No chimp call clips found in input\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEGqTCXdV-Wt"
      },
      "source": [
        "#Show the predcited call type labels for the entire recording\n",
        "pretty_print(df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}